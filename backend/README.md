# 南京大学信息聚合平台
## 一、项目说明
### 1.1 项目名称
南京大学信息聚合平台
（NJU Information Aggregation Platform）

可访问47.122.71.85
（当天最新消息可能无法及时更新，需一天结束后进行总爬取，但未来的DDL是可显示的）
也可本地运行，git clone后按以下方式运行，但为保护数据库，api等隐私，本地只显示静态页面，无数据：
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
uv sync
#激活虚拟环境，不同系统和终端命令可能不同
python backend/run.py
#请切换终端保持后端运行
cd frontend 
pnpm install
pnpm run dev
```

### 1.2 项目简介
各种截止日期常常让我们焦头烂额，一不小心就错过关键DDL；重要通知淹没在各种信息源中，我们在这样庞大的信息海洋里感到快要窒息……
别担心！南京大学信息聚合平台 (NJU-IAP) 正是为解决这些困扰而生，做你的校园信息管家，帮你轻松应对！
我们构建自动爬虫抓取散落在南大官网、公众号等地方的信息（讲座、比赛、志愿活动等），AI智能整理后呈现给你：DDL提醒，每日消息，智能检索助手。
助你：信息获取更便捷，时间规划更轻松，校园生活更舒心

### 1.3 项目成员及分工
| 成员 | 专业 | 分工 |
| --- | --- | --- |
| 陈宣霖 | 智能科学与技术 | 统筹规划、爬虫开发、后端逻辑 |
| 刘洋铭 | 智能科学与技术 | 数据库设计、查询设计、原始数据处理 |
| 嵇煜人 | 智能科学与技术 | 前端开发、交互设计、爬虫开发 |
| 陈化之 | 数字经济 | 查询设计、数据清洗 |


### 1.4 项目参考资料
+ 技术框架：Vue 3官方文档、Flask开发指南、MySQL数据库设计手册
+ 算法参考：RAG（检索增强生成）技术、MCP（模型上下文协议）调用
+ 合规依据：《个人信息保护法》《网络安全法》及各信息源爬取协议。

### 1.5 项目技术栈
+ **前端**：Vue 3.5.13 + TypeScript 5.8 + Vite 6.x + Naive UI 2.41.0 + Vue Router 4.5.x（响应式组件、状态管理、路由优化）。
+ **后端**：Flask框架 + SQLAlchemy ORM + Python 3.10（RESTful API设计、数据库交互）。
+ **数据库**：MySQL 8.0（云端部署于阿里云ESC，19张业务表分类存储，支持SSL加密）。
+ **爬虫**：Python爬虫脚本（Selenium + BeautifulSoup，支持网页、微信公众号数据采集）。
+ **AI模块**：大模型语义分析 + RAG + MCP技术（信息清洗+结构化处理+推送+查询）。

## 二、快速开始
### 2.1 使用方式
访问公网47.122.71.85
### 2.2 使用示例
+ **首页**：包含三个跳转框，对应：信息中心，AI助手，关于我们/个性化设置，侧标栏可切换页面，右上角为登录端，不同用户后端会记录其自定义DDL和数据源偏好
+ **信息中心**：包含每日消息（来自微信公众号，官网，慕课等），DDL提醒，两者通过下方日历视图切换日期，默认当日，支持按时间/类型筛选，支持自定义添加个性DDL。
+ **AI助手（蓝鲸助手）**：输入“本周学术讲座”，系统自动检索数据库并返回相关信息摘要及原文链接。用户根据不同需要自行选择是否开启“深度查询”模式（速度较慢，精确度高）
+ **关于我们/个性化设置**：自主选择所需的和优先考虑的数据源，满足用户喜好和个性化需求

## 三、功能列表
### 3.1 核心功能
1. **多源信息聚合**
    - **多元数据源**：支持微信公众号（20+）、学校官网、慕课平台等多类型数据源自动化爬取。
    - **每日更新**：通过自动化脚本，每日爬取最新发布的信息并加入数据库
2. **智能信息处理**
    - **数据清洗**：使用丰富的系统prompt搭建Agent，自动提取时间、对象、地点等关键信息，过滤无效内容。
    - **结构化储存**：云端数据库结构化存储19类信息（比赛通知、志愿活动、国际交流等），每张表包含原文链接确保可追溯。
    - **检索与生成**：采取RAG和MCP两种技术，实现用户提问的语义解析与精准匹配，支持多轮追问。
3. **用户交互与提醒**
    - **日历视图DDL提醒**：自动同步DDL至日历，支持自定义添加个性DDL。
    - **今日消息总结**：AI生成每日信息简报，分多个类型，可快速浏览重点内容。

### 3.2 特色功能
+ **一站式交互**：创新性地将信息推送，日历视图，智能问答深度融合，提供一站式的获取AI总结通知，DDL自动化提醒以及“一问即答”的沉浸式体验。
+ **个性化处理**：用户自定义调整信息源，如选择公众号，且可添加个性DDL作为Todo清单
+ **查询选择**：默认为RAG查询，文本向量化匹配问答方式，速度快；深度查询使用MCP查询，相比RAG能更深入理解用户意图，提升准确度。
+ **低人工成本运营**：自动化信息流闭环（爬取→处理→推送→追问），减少人工查询和整理信息的时间成本。，仅需少量审核即可发布。
+ **跨平台适配**：采用前后端分离技术，后端专注数据爬取处理以及AI 工作流，前端聚焦信息展示与用户交互，未来可拓展到手机移动端

## 四、开发说明
### 4.1 文件结构
主要分为

1. **/（配置文件）**
2. **backend（后端）**
3. **frontend（前端）**
4. **crawlers（爬虫）**
5. **database（数据库）**
6. **information_processing（信息处理）**

```plain
NJU_IAP/
|——.gitignore                          # Git忽略文件配置
|——.idea/                              # IDE配置目录
|——.github/	  						   # 更新服务器脚本
|——README.md                           # 项目说明文档
|——uv.lock							   # uv包管理
|——pyproject.toml                      # Python项目配置文件
|
|——backend/                            # 后端服务目录
|   |——app/                            # 应用主目录
|       |——__init__.py
|       |——app.py                      # 应用配置
|       |——db.py                       # 数据库配置
|       |——settings.py                 # 配置
|       |——models/                     # 模型目录
|       |   |——__init__.py
|       |   |——user.py				   # 用户模型		
|       |——routes/                     # 路由目录
|       |   |——__init__.py
|       |   |——api_routes.py           # API路由定义
|       |——services/                   # 服务层目录
|       |   |——__init__.py
|       |   |——news_service.py         # 新闻服务
|       |   |——query_service.py        # 查询服务
|       |   |——ddl_service.py          # ddl服务
|   |——run.py                          # 应用运行脚本
|   |——test.py                         # 测试文件
|
|——crawlers/                           # 爬虫模块目录
|   |——web/                            # 网页爬虫
|   |   |——nju_news.py                 # 南大新闻爬虫
|   |   |——five_education.py           # 南大五育爬虫
|   |   |——mooc.py                     # 慕课爬虫
|   |   |——xxt.py                      # 学习通爬虫
|   |——wechat/                         # 微信公众号爬虫
|   |   |——api.py                      # 微信公众号API接口
|   |   |——crawler.py                  # 微信爬虫实现
|
|——database/ 			   			   # 数据库相关目录
|   |——create_sql/                     # 数据库结构sql语句
|
|——frontend/                           # 前端目录
|   |——.gitignore                      # 前端Git忽略文件
|   |——doc.md                          # 前端文档
|   |——package.json                    # 前端项目依赖配置
|   |——pnpm-lock.yaml                  # 前端依赖锁定文件
|   |——src/                            # 前端源代码目录
|   |   |——assets/                     # 静态资源
|   |   |——components/                 # 可复用组件
|   |   |——resource/                   # 国际化资源和文本
|   |   |——router/                     # 路由配置
|   |   |——services/                   # 数据服务
|   |   |——views/                      # 页面视图组件
|   |——tsconfig.node.json              # 前端TypeScript配置
|
|——information_processing/             # 信息处理模块
|   |——README.md                       # 模块说明文档
|   |——ai_processing.py                # 主执行程序，完成信息处理，导入数据库的工作
|   |——prompt/          			   # 数据结构化的提示词
|   |——db_importer.py                  # json导入模块

```

### 4.2 模块概要
#### 模块关系图
![](https://cdn.nlark.com/yuque/__mermaid_v3/b64172f9fd23f0c620036837947bb219.svg)



## 五、遇见的问题和解决方法
### 5.1 数据源分散
+ **问题：** 用户所需数据源分散，包含微信公众号，网页，慕课等
+ **解决：开发爬虫模板，同时结合多元技术**
    - 针对微信公众号，网页开发不同的模版，在一个模板内对同一类型数据批量爬取
    - 运用多种技术，如Selenium，BeautifulSoup，RSS等方法，解决不同模板遇到的特定爬取问题


### 5.2 数据形式多样且纷杂
+ **问题：**数据来源多样导致数据形式多元，包含无效数据，且为非结构化的自然语言文本
+ **解决：结合AI语义处理设计数据清洗和结构化工作流**
    - 设计提示词和人工处理过的带标签数据（有效/无效）进行初步数据清洗
    - 将校园信息资源**按内容特征**划分为19个独立数据表，**主动构建分层关键词体系**（见下文MCP处）并进行json结构化存入数据库


### 5.3 查询调用延迟
+ **问题：** 数据库查询响应时间过长（>10秒），导致用户体验显著下降。
+ **解决：采用双模式检索方案：**
    - **RAG 即时响应层**：处理常规查询，返回秒级结果，保障基础体验。
    - **MCP 精准分析层**：面向具有高精度需求的用户，提供深度检索
    - **等待体验优化**：
        * 执行 MCP 查询时**实时推送进度状态**。
        * 通过**进度可视化**缓解用户等待焦虑，提升过程可感知性，提升用户心理体验。
    - **信息预处理**：
        * 提前将用户的需求分为5类，封装成5个对应的Agent。
        * 在RAG查询时，让LLM根先据用户问题来判断所需调用的Agent，以减少不必要的Agent调用，来**提升回答的速度**和回答的信息准度。


### 5.4 传统RAG方法检索准确度较低
+ **问题：** 当文本规模扩大，原始文档噪声激增，关键信息被淹没，RAG 召回准确率降低。
+ **解决：结构化提纯 + MCP 精准检索双方案**
    1. **信息提纯**：
        * 设计**结构化模板**，信息呈现结构更清晰。
        * 提炼原文关键信息，生成**高密度结构化数据**，减少噪声干扰。
    2. **精准检索**：
        * 基于结构化数据，采用 **MCP 深度检索**


### 5.5 MCP检索部分
+ **问题一：复杂多表结构导致模型混淆与错误**
    - **描述：** 为提升信息精度，MCP采用按文章类型分表存储结构化数据（每类型对应独立数据库表）。然而，当数据库包含**大量类型（表）且结构复杂**时，大模型因**有限注意力机制**难以精确记忆所有表结构细节，导致：
        1. **检索准确度下降：** 模型可能混淆不同表的结构或查询规则。
        2. **MCP执行报错率升高：** 错误的结构引用或查询语句生成导致流程频繁中断。
    - **解决：智能体分治策略**
        * 为MCP检索模块部署**多个专用智能体（Agents）**。
        * 每个智能体**仅负责特定子集类型（表）** 的检索任务。
        * **优势：**
            + **保留注意力：** 单个智能体只需专注有限表结构，大幅降低认知负荷。
            + **并发处理：** 智能体可**并行执行**各自负责的检索任务，提升效率。
            + **降低错误：** 职责明确，减少跨表混淆导致的执行错误。
+ **问题二：语义泛化能力不足，近义词匹配困难**
    - **描述：** MCP检索在处理用户查询时，对**同义/近义词汇**的识别和匹配能力较弱，导致无法有效召回相关但表述不同的关键信息。
    - **解决：双层提示词优化语义理解**
    - 在**数据处理（入库）** 和 **查询执行** 两个关键环节加入语义泛化提示：
        1. **数据入库提示词 (结构化阶段)：**
            + 指导处理模型在填充结构化模板时，**主动构建分层关键词体系**。
            + 要求总结**从“高度概括”到“高度独特”** 的系列关键词。
            + **例 (以EL程序大赛为例)：**
                - 概括层：`**程序**`， `**编程**`， `**算法**`
                - 特定层：`**EL程序大赛**`， `**EL比赛**`
                - 独特层：`**EL**` 
        2. **查询执行提示词 (检索阶段)：**
            + 在MCP智能体执行查询前，提示词明确要求其**主动考虑查询关键词的潜在近义词、同义词和相关表述**。
            + 指导智能体利用入库时构建的分层关键词进行**语义扩展检索**。
    - **优势：**
        * **增强召回：** 显式提示促使模型考虑语义多样性，提升匹配相关内容的概率。
        * **结构化解耦：** 语义优化分别作用于数据准备和查询执行，互不干扰且协同增效。

## 六、不足之处与展望
### 6.1 不足之处
+ **数据源覆盖有限**：目前仅支持20+公众号和5+网页，未接入教务系统、邮件等内部渠道。
+ **数据提取泛化能力不足**：对格式复杂的海报图片等尚未解析，需进一步实现OCR技术集成。
+ **用户量验证不足**：尚未在全校范围推广，目前位于测试阶段，需验证大规模并发下的系统稳定性。
+ **数据来源类型较为单一**：暂时无法处理语音，视频类信息源，待后续扩充多模态

### 6.2 未来展望
目前已进入**系统集成**中期阶段

**已完成**：爬虫，前端基础页面，后端基础框架，检索Agent和数据清洗结构化Agent的搭建，阿里云数据库搭建

**待完成**：Agent微调，前端界面美化以及交互优化，大规模运用场景下的改造，信息源数量拓展和质量筛选

| 阶段 | 周期 | 交付物 | 验证指标 |
| --- | --- | --- | --- |
| MVP验证 | 第 1 - 3 周 | 基础信息爬取模块+简易前端展示页面+云端数据库 | 覆盖10+公众号，5+学校网页和慕课，推送信息完整度和AI总结精确度≥90% |
| 系统集成 | 第 4 - 6 周 | 完整后端业务逻辑+前后端接口联调+前端交互优化 | 检索响应时间<2秒，平台运行流畅 |
| 商业落地 | 第 7 - 9 周 | 南大试点运营平台+用户测试反馈收集+同步移动端 | 与南大以及多家高校达成合作，日活用户≥5000，用户满意度≥90% |


+ **功能扩展**：
    - 集成机器学习推荐算法，提升个性化推送精度。
    - AI助手添加长期记忆功能，根据用户画像实现个性化推送。
+ **生态构建**：
    - 与“南哪消息”等学生团体合作，降低人工审核成本。
    - 向其他高校输出技术框架，打造跨校信息聚合平台。
    - 扩展信息源，覆盖教务系统，邮件等
+ **技术升级**：
    - 结合多模态大模型运用，实现海报、视频等非结构化数据的智能处理。
    - 开发移动端APP，支持推送通知和离线浏览。



## 七、项目源码
+ 仓库地址：[https://github.com/xuanlin-chen/NJU_IAP](https://github.com/xuanlin-chen/NJU_IAP)，选择main分支



